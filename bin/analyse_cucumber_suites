#!/usr/bin/env python3
import sqlite3
import json
import sys
import os
from statistics import mean, stdev

DB_FILE = "cucumber_analysis.db"

def setup_database():
    """
    Sets up the SQLite database with the necessary tables if they don't exist.
    """
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    cursor.execute("""
    CREATE TABLE IF NOT EXISTS runs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        commit_id TEXT,
        project_name TEXT,
        suite_time REAL,
        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
    )
    """)

    cursor.execute("""
    CREATE TABLE IF NOT EXISTS steps (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        run_id INTEGER,
        test_name TEXT,
        step_name TEXT,
        step_time REAL,
        FOREIGN KEY(run_id) REFERENCES runs(id)
    )
    """)

    conn.commit()
    conn.close()

def store_data(commit_id, project_name, suite_time, steps):
    """
    Stores the data from the Cucumber report into the database.
    """
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    cursor.execute("""
    INSERT INTO runs (commit_id, project_name, suite_time)
    VALUES (?, ?, ?)
    """, (commit_id, project_name, suite_time))

    run_id = cursor.lastrowid

    for test_name, step_name, step_time in steps:
        cursor.execute("""
        INSERT INTO steps (run_id, test_name, step_name, step_time)
        VALUES (?, ?, ?, ?)
        """, (run_id, test_name, step_name, step_time))

    conn.commit()
    conn.close()

def parse_report(report_path):
    """
    Parses the Cucumber JSON report and extracts step timings.
    """
    with open(report_path, 'r') as file:
        data = json.load(file)

    steps = []
    total_time = 0

    for feature in data:
        for scenario in feature.get("elements", []):
            test_name = scenario.get("name", "Unnamed Scenario")
            for step in scenario.get("steps", []):
                step_name = step.get("name", "Unnamed Step")
                result = step.get("result", {})
                duration = result.get("duration", 0) / 1e9  # Convert nanoseconds to seconds
                steps.append((test_name, step_name, duration))
                total_time += duration

    return total_time, steps

def analyze(commit_id):
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    cursor.execute("SELECT suite_time FROM runs")
    suite_times = [row[0] for row in cursor.fetchall()]

    if len(suite_times) < 2:
        print("Not enough data to perform analysis.")
        conn.close()
        return

    mean_time = mean(suite_times)
    std_dev = stdev(suite_times)
    current_time = suite_times[-1]
    previous_time = suite_times[-2]

    difference = current_time - previous_time

    print(f"Commit ID: {commit_id}")
    print(f"Overall suite time difference: {difference:.2f} seconds")

    if abs(difference) > std_dev * 2:  # Unusual change if > 2 standard deviations
        print(f"Unusual change detected! Previous mean time: {mean_time:.2f}, StdDev: {std_dev:.2f}")

    # Find slow tests
    cursor.execute("""
    SELECT s.test_name, SUM(s.step_time) AS total_time
    FROM steps s
    JOIN runs r ON s.run_id = r.id
    WHERE r.commit_id = ?
    GROUP BY s.test_name
    ORDER BY total_time DESC
    LIMIT 5
    """, (commit_id,))

    print("\nTop 5 slowest tests:")
    for row in cursor.fetchall():
        print(f"Test: {row[0]}, Time: {row[1]:.2f} seconds")

    conn.close()

def main():
    if len(sys.argv) != 4:
        print("Usage: python analyze_cucumber.py <commit_id> <project_name> <report_path>")
        sys.exit(1)

    commit_id, project_name, report_path = sys.argv[1:4]

    if not os.path.exists(report_path):
        print(f"Error: Report file '{report_path}' not found.")
        sys.exit(1)

    setup_database()

    suite_time, steps = parse_report(report_path)
    store_data(commit_id, project_name, suite_time, steps)
    analyze(commit_id)

if __name__ == "__main__":
    main()
